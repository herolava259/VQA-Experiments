{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "64ef48d4-f6e6-4758-8fbd-ab4840f7b338",
   "metadata": {},
   "source": [
    "# Fine-Tuning Transformers with MLflow for Enhanced Model Management"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c7be24c-8b42-4b65-bdd9-bfd01cda9f78",
   "metadata": {},
   "source": [
    "### Role of MLflow in Model Lifecycle \n",
    "\n",
    "- Training Cycle Logging: Keeping a detailed log of the training cycle, including parameters, metrics and intermediate results\n",
    "- Model Logging and Management: Separately logging the trained model, tracking its version and managing its life lifecycle post-training\n",
    "- Inference and Deployment: Using the logged model for inference, ensuring easy transition from training to deployment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fe5a6751-04bf-4cd1-aaa4-7698ad32224d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: TOKENIZERS_PARALLELISM=false\n"
     ]
    }
   ],
   "source": [
    "%env TOKENIZERS_PARALLELISM=false\n",
    "\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a3505ab-d80e-4d14-aff0-c1dd3f4dad8e",
   "metadata": {},
   "source": [
    "### Preparing the Dataset and Environment for Fine Tuning \n",
    "#### Key steps for this section\n",
    "\n",
    "1. **Loading the Dataset**\n",
    "2. **Splitting the Dataset**\n",
    "3. **Importing Neccessary Libraries**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e73e56c3-c621-45d4-913c-7cd1c1c418a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import evaluate \n",
    "import numpy as np \n",
    "from datasets import load_dataset\n",
    "\n",
    "from transformers import (\n",
    "    AutoModelForSequenceClassification,\n",
    "    AutoTokenizer,\n",
    "    Trainer,\n",
    "    TrainingArguments,\n",
    "    pipeline,\n",
    ")\n",
    "\n",
    "import mlflow \n",
    "\n",
    "sms_dataset = load_dataset(\"sms_spam\")\n",
    "\n",
    "# split train/test by an 8/2 ratio \n",
    "\n",
    "sms_train_test = sms_dataset[\"train\"].train_test_split(test_size=0.2)\n",
    "train_dataset = sms_train_test[\"train\"]\n",
    "test_dataset = sms_test_test[\"test\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c536bdf3-0265-4fb1-a10c-2281636a0da4",
   "metadata": {},
   "source": [
    "### Tokenization and Dataset Preparation \n",
    "#### Tokenization Process \n",
    "- **Loading the Tokenizer**\n",
    "- **Defining the Tokenization Function**\n",
    "- **Applying Tokenization to the Dataset**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9f8aa4f-59cf-42bf-bfe7-a23bd1cc5209",
   "metadata": {},
   "outputs": [],
   "source": [
    "# loading tokenizer \n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"distillbert-base-uncased\")\n",
    "\n",
    "def tokenize_function(examples):\n",
    "\n",
    "    return tokenizer(\n",
    "        examples[\"sms\"],\n",
    "        padding=\"max_length\",\n",
    "        truncation=True,\n",
    "        max_length=128,\n",
    "    )\n",
    "\n",
    "seed=22\n",
    "\n",
    "\n",
    "# transform data to input of model \n",
    "\n",
    "train_tokenized = train_dataset.map(tokenize_function)\n",
    "train_tokenized = train_tokenized.remove_columns([\"sms\"]).shuffle(seed=seed)\n",
    "\n",
    "test_tokenized = test_dataset.map(tokenize_function)\n",
    "test_tokenized = test_tokenized.remove_comlumns([\"sms\"]).shuffle(seed=seed)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6df55625-d19e-43a8-8d0d-510ccb827966",
   "metadata": {},
   "source": [
    "### Model Initialization and Label Mapping \n",
    "#### Setting up Labels Mapping \n",
    "- Defining Label Mappings\n",
    "#### Initializing the Model \n",
    "- Model Selection\n",
    "- Model Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0804351-5485-4901-87f2-d02eca0f9e7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# label mapping \n",
    "id2label = {0: \"ham\", 1: \"spam\"}\n",
    "label2id = {\"ham\": 0, \"spam\": 1}\n",
    "\n",
    "# model selection \n",
    "\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\n",
    "    \"distillbert-base-uncased\",\n",
    "    num_label=2,\n",
    "    label2id=label2id,\n",
    "    id2label=id2label,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03129664-f71a-4d90-83e1-103d38a9da38",
   "metadata": {},
   "source": [
    "### Setting up Evaluation Metrics\n",
    "\n",
    "#### Choosing and Loading the Metric \n",
    "- Metric Selection\n",
    "- Loading the metric\n",
    "#### Defining the Metric Computation Function\n",
    "- Function for Metric Computation\n",
    "- Processing Prediction\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d44fe28-9e93-479e-9515-ef6ee3d66cf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "metric = evaluate.load(\"accuracy\")\n",
    "\n",
    "def compute_metrics(eval_pred):\n",
    "    logits, labels = eval_pred\n",
    "    predictions = np.argmax(logits, axis=-1)\n",
    "\n",
    "    return metric.compute(predictions=predictions, references=labels)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1e80dd9-4b49-48ad-9056-ba521cbaad8d",
   "metadata": {},
   "source": [
    "### Configuring the Training Environment \n",
    "\n",
    "#### Training Arguments Configuration\n",
    "- **Defining the Output Directory**\n",
    "- **Specifying Training Arguments**\n",
    "\n",
    "#### Initializing the Trainer\n",
    "- **Creating the Trainer Instance**\n",
    "- **Role of the trainer**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f997ba63-fb22-46e7-8e57-217918e3edb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_output_dir = \"/tmp/sms_trainer\"\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir = training_output_dir,\n",
    "    evaluation_strategy = \"epoch\",\n",
    "    per_device_train_batch_size=8,\n",
    "    per_device_eval_batch_size=8,\n",
    "    logging_steps=8,\n",
    "    num_train_epochs=3\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_tokenized,\n",
    "    eval_dataset=test_tokenized,\n",
    "    compute_metrics=compute_metrics\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "381180d6-9296-47bb-94f6-d14dd237b81c",
   "metadata": {},
   "outputs": [],
   "source": [
    "mlflow.set_tracking_uri(\"http://localhost:8080\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d55eabd-69c3-4b00-9602-834a6572db0d",
   "metadata": {},
   "source": [
    "### Intergrating MLflow for Experiment Tracking \n",
    "\n",
    "#### Setting up the Experiment\n",
    "- **Naming the Experiment**\n",
    "- **Role of MLFlow in Training**\n",
    "\n",
    "#### Benefits of Experiment Tracking \n",
    "\n",
    "- **Organization**: Keeps your training runs organized and easily accessible.\n",
    "- **Comparability**: Allow for easy comparison of different training runs to understand the impact of changes in parameters or data\n",
    "- **Reproducibility**: Enhances the reproducibility of experiments by logging all necessary details "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddb0905d-ba09-4eac-bd3a-05f630043dcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "mlflow.set_experiments(\"Spam Classifier Training\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73c5bfb3-f58c-4d1c-9dbf-b7cf194318f5",
   "metadata": {},
   "source": [
    "### Starting the Training Process with MLFlow \n",
    "\n",
    "#### Initiating the MLFlow run \n",
    "\n",
    "- Starting an MLFlow Runs\n",
    "- Training the model\n",
    "\n",
    "#### Monitoring the training progress \n",
    "\n",
    "- **Loss**\n",
    "- **Learning rate**\n",
    "- **Epoch Progress**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f53e39f8-6fb1-4975-b9fe-468ce2d0ae1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "with mlflow.start_run() as run:\n",
    "    trainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd292da0-9d95-4a33-b4be-f884d73b1389",
   "metadata": {},
   "source": [
    "### Creating a Pipeline with the Fine-Tuned Model \n",
    "\n",
    "#### Setting up Inference Pipeline \n",
    "- Pipeline Creation\n",
    "- Model Intergration\n",
    "- Configuring the Pipeline\n",
    "\n",
    "#### Device Configuration for Different Platforms \n",
    "#### Importance of a Customized Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5d5cce4-80bf-4311-afed-1f77ac40594b",
   "metadata": {},
   "outputs": [],
   "source": [
    "tunned_pipeline = pipeline(\n",
    "    task = \"text-classification\",\n",
    "    model = trainer.model,\n",
    "    batch_size= 8,\n",
    "    tokenizer=tokenizer,\n",
    "    device=\"mps\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d487b36c-67db-4b4b-8e6f-ad5fe6d546d3",
   "metadata": {},
   "source": [
    "### Validating the Fine-Tuned Model \n",
    "\n",
    "#### Importance of Model Validation\n",
    "\n",
    "- **Assessing Model Performance**\n",
    "- **Avoiding Costly Redo's**\n",
    "\n",
    "#### Evaluating with a Test query \n",
    "- **Test Query**\n",
    "- **Observing the Output**\n",
    "\n",
    "#### Validating Before Logging to MLFlow "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6abf9b0f-a2db-472d-a34f-4ba78993d1ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "quick_check = ( \"I have a question regarding the project development timeline and allocated resources; \"\n",
    "  \"specifically, how certain are you that John and Ringo can work together on writing this next song? \"\n",
    "  \"Do we need to get Paul involved here, or do you truly believe, as you said, 'nah, they got this'?\")\n",
    "\n",
    "tunned_pipeline(quick_check)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e99f6ffe-095f-4f33-9276-5c886926f9a4",
   "metadata": {},
   "source": [
    "### Model Configuration and Signature Inference \n",
    "\n",
    "#### Configuring the Model for MLflow \n",
    "\n",
    "- **Setting Model Configuration:**\n",
    "\n",
    "#### Inferring the Model Signature \n",
    "\n",
    "- **Purpose of Signature Inference**\n",
    "- **Using mlflow.models.infer_signature**\n",
    "- **Including Model Parameters**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8050c5a-0fd0-428e-98f8-af4a5e6a37b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_config = {\"batch_size\": 8}\n",
    "\n",
    "signature = mlflow.models.infer_signature(\n",
    "    [\"This is a test!\", \"And this is also a test.\"],\n",
    "    mlflow.transformers.generate_signature_output(\n",
    "        tunned_pipeline, [\"This is a test response!\", \"So is this.\"]\n",
    "    ),\n",
    "    params=model_config\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41ef5b75-fa30-4b0e-9af2-087d471a38da",
   "metadata": {},
   "source": [
    "### Logging the Fine-tuned model to MLFlow \n",
    "\n",
    "#### Accessing the existing Run used for training \n",
    "\n",
    "- **Initiating MLFlow Run:**  We start a new run in MLflow using mlflow.start_run(). This new run is specifically for the purpose of logging the model, separate from the training run.\n",
    "\n",
    "#### Logging the Model in MLFlow \n",
    "- **Using mlflow.transformers.log_model:** We log our fine-tuned model using this function. It's specially designed for logging models from the Transformers library, making the process streamlined and efficient.\n",
    "- **Specifying Model Information:**\n",
    "      +. transformer_model\n",
    "      +. artifact_path\n",
    "      +. signature\n",
    "      +. input_example\n",
    "      +. model_config\n",
    "\n",
    "#### Importance of Model Logging \n",
    "\n",
    "- Version Control\n",
    "- Model Management\n",
    "- Reproducibility and Sharing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93cee7b3-d9ac-46fc-8140-0df9386c5dcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "with mlflow.start_run(run_id=run.info.run_id):\n",
    "    model_info = mlflow.transformers.log_model(\n",
    "        transformers_model=tunned_pipeline,\n",
    "        artifact_path=\"fine_tuned\",\n",
    "        signature=signature,\n",
    "        input_example=[\"Pass in a string\", \"And have it mark as spam or not.\"],\n",
    "        model_config=model_config,\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d2ff95a-9670-441e-b1a1-7db544ef507e",
   "metadata": {},
   "source": [
    "### Loading and Testing the Model from MLFlow\n",
    "\n",
    "#### Loading the Model from MLFlow \n",
    "\n",
    "- **Using mlflow.transformers.load_model**\n",
    "- **Retrieving Model URI**\n",
    "\n",
    "#### Testing the Model with Validation Text\n",
    "\n",
    "- **Preparing Validation Text**\n",
    "- **Evaluating Model Output**\n",
    "\n",
    "##### Testing the model after loading it from MLFlow is essential for serveral reasons:\n",
    "- **Validation of Logging Process**\n",
    "- **Practical Performance Assessment**\n",
    "- **Demonstrating End-to-end Workflow:** Showcases a complete workflow from training, logging, loading, to using the model, which is vital for understanding the entire model lifecycle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1436463-9874-4371-b1dd-7dc56f4e0513",
   "metadata": {},
   "outputs": [],
   "source": [
    "loaded = mlflow.transformers.load_model(model_uri=model_info.model_uri)\n",
    "\n",
    "validation_text = (\n",
    "    \"Want to learn how to make MILLIONS with no effort? Click HERE now! See for yourself! Guaranteed to make you instantly rich! \".\\,\n",
    "    \"deploy-chatbot-server.ipynbon't miss out you could be a winner!\"\n",
    ")\n",
    "\n",
    "loaded(validation_text)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
